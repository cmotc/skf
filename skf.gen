#!/usr/bin/env bash

#  skf.gen
#  
#  Copyright 2013 Samir Chaouki <moebiuseye@jeannedhack.org>
#  
#  This program is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#  
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#  
#  You should have received a copy of the GNU General Public License
#  along with this program; if not, write to the Free Software
#  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
#  MA 02110-1301, USA.



#Â Importing libs
source "$SHARE_DIR/lib/"*

# Setting canonical paths
SRC="$(readlink -m "$1")"
DST="$(readlink -m "$2")"


# recreating destination directory if not present 
mkdir -p -- "$DST"

echoerr "SRC:$SRC"

# Just to be sure that this is actualy a website. 
if [ -d "$SRC" ] && [ -f "$SRC/.skfrc" ] 
then 
    echoerr "Detected Website dir \"$SRC\"."
else 
    echo "Invalid directory \"$SRC\". This should never happen! "
    exit 1 
fi

# importing directory configuration file
source "$SRC/.skfrc"

stripped_url="$base_url"
[[ -z "$scheme" ]] && export scheme="$(echo "$base_url" | grep -o -E '^http(s?)')"
[[ -z "$scheme" ]] || export stripped_url="$(echo "$base_url" | sed "s/${scheme}://")"
base_url="$stripped_url"

# loading specified plugin if present 
if [ -f "$SHARE_DIR/plugins/$plugin.sh" ]
then
    source "$SHARE_DIR/plugins/$plugin.sh"
else
    echoerr "Plugin not found $SHARE_DIR/plugins/$plugin.sh"
    exit
fi

# Copying static files to the destination 
get_staticfiles () { 
    echo_them () { 
        while read line 
        do [ -z "$line" ] || echo "$SRC/$line" 
        done
    }
    if [ -f "$SRC/.skf.static" ]
    then
        echo_them < "$SRC/.skf.static"
    else 
        if ! [ -z "$staticlist" ]
        then
            printf "%s" "$staticlist"  | echo_them 
        else
            echoerr "Static files are not defined. "
            echoerr "Will not copy anything. "
        fi
    fi
    unset echo_them
}

staticfiles="$(get_staticfiles)"
unset get_staticfiles
echoerr staticfiles "$staticfiles"

# Copying every static file into destination. 
[ -z "$staticfiles" ] || echo "$staticfiles" | while read staticfile 
do 
    find "$SRC" -wholename "$staticfile" 2> /dev/null | while read sf 
    do
        [ -z "$sf" ] && continue
        tmp="${sf/$SRC/$DST/}"
        mkdir -p -- "${tmp%/*}"
        echoerr cp_tree "$(readlink -f "$sf")" "${sf/$SRC/$DST/}" 
        cp_tree "$(readlink -f "$sf")" "${sf/$SRC/$DST/}" 
    done
done

###################################
#                                 #
#   This generates the website.   #
#                                 #
###################################
t_skf_gen

# The here-below part is only for recursive
[ -z "$RECURSIVE" ] && exit 0


readarray -t WEBSITES < <(find "$SRC"/*  -maxdepth 0 -type d -exec cp '{}'/.skfrc /dev/null \; -print 2> /dev/null )

echoerr "${!WEBSITES[@]}"
for k in ${!WEBSITES[@]}
do
    websrc="${WEBSITES[$k]}"
    [ -d "$websrc" ] || exit
    [ -z "$websrc" ] && exit
    webdst="$(readlink -m "$DST_DIR${websrc#$SRC_DIR}")"
    echoerr "webdst:$webdst"
    skf.gen "$websrc" "$webdst"
done
unset k
unset websrc

[ "$SRC" == "$SRC_DIR" ] &&  echo "Your website should be visible at ${scheme}${base_url}index.html "


[ -z "$WATCH" ] && exit 0
[ "$SRC_DIR" == "$SRC" ] || exit 0 


get_dirhash () { 
    tree -a --timefmt "%s" -F --prune -i -f "$SRC" | grep -v -E '/$' | md5sum
}

# Watching changes in SRC_DIR directory 
export WATCH=""
dirhash="$(get_dirhash)"
while sleep 3
do
    newdirhash="$(get_dirhash)"
    if    [ "$dirhash" != "$newdirhash" ]
    then
        echo
        echo "something changed. Regenerating and watching..."
        
        skf.gen "$SRC" "$DST"
        
        # Sleep an extra 5 seconds. Because you deserved it. 
        dirhash="$(get_dirhash)"
        sleep 5
        continue
    fi
    dirhash="$(get_dirhash)"
done
